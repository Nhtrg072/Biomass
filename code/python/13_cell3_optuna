# =========================================================================
# TỐI ƯU THAM SỐ MÔ HÌNH VỚI OPTUNA
# =========================================================================
PERCENTILE_TO_REMOVE = 20
YEAR_TO_CALCULATE = 5

OPTUNA_CONFIG = {
    'n_trials': 50,
    'sample_size': 10000,
    'n_boost_round': 100,
    'early_stopping': 20
}

EXPORT_PATH = Path("/content/drive/MyDrive/data/Biomass_all_Model_Training")

print(f"\nCấu hình Optuna:")
print(f"Lọc nhiễu: {PERCENTILE_TO_REMOVE}%, Trials: {OPTUNA_CONFIG['n_trials']}, Sample: {OPTUNA_CONFIG['sample_size']:,}")

# Tải dữ liệu
df_train_filtered = pd.read_csv(EXPORT_PATH / f'train_filtered_for_{YEAR_TO_CALCULATE}_years_{PERCENTILE_TO_REMOVE}.csv')
df_val_filtered = pd.read_csv(EXPORT_PATH / f'val_filtered_for_{YEAR_TO_CALCULATE}_years_{PERCENTILE_TO_REMOVE}.csv')
feature_info = joblib.load(EXPORT_PATH / f'filter_metadata_final_for_{YEAR_TO_CALCULATE}_years.joblib')

FEATURE_COLUMNS = ['agbd_predict', 'dem', 'slope', 'Dist_Rivers', 'Dist_Urban', 'rainfall', 'temperature']
TARGET_COLUMN = feature_info['target_variable']

# Chuẩn bị dữ liệu
X_val = df_val_filtered[FEATURE_COLUMNS]
y_val = df_val_filtered[TARGET_COLUMN]

n_samples = min(OPTUNA_CONFIG['sample_size'], len(df_train_filtered))
df_train_optuna = df_train_filtered.sample(n=n_samples, random_state=42)
X_train_optuna = df_train_optuna[FEATURE_COLUMNS]
y_train_optuna = df_train_optuna[TARGET_COLUMN]

print(f"Lấy {len(df_train_optuna):,} mẫu để tune")

# Định nghĩa objective
def objective(trial):
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'verbosity': -1,
        'seed': 42,
        'num_leaves': trial.suggest_int('num_leaves', 20, 150),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
    }

    train_data = lgb.Dataset(X_train_optuna, label=y_train_optuna)
    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

    model = lgb.train(
        params, train_data,
        num_boost_round=OPTUNA_CONFIG['n_boost_round'],
        valid_sets=[val_data],
        callbacks=[
            lgb.early_stopping(stopping_rounds=OPTUNA_CONFIG['early_stopping'], verbose=False),
            lgb.log_evaluation(period=0)
        ]
    )

    y_pred = model.predict(X_val, num_iteration=model.best_iteration)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse

# Chạy Optuna
print("\nĐang chạy Optuna...")
study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))
study.optimize(objective, n_trials=OPTUNA_CONFIG['n_trials'], show_progress_bar=True)

best_params = study.best_params
best_rmse = study.best_value

print(f"\nTối ưu hoàn tất! Best RMSE: {best_rmse:.4f}")
print(f"\nBest Hyperparameters:")
for key, value in best_params.items():
    print(f"  {key}: {value}")

# Lưu tham số
output_file = EXPORT_PATH / f'best_optuna_params_for_{YEAR_TO_CALCULATE}_years.joblib'
joblib.dump(best_params, output_file)
print(f"\nĐã lưu tham số: {output_file.name}")

# Cleanup
del df_train_filtered, df_val_filtered, feature_info, X_val, y_val
del df_train_optuna, X_train_optuna, y_train_optuna, study, best_params
gc.collect()

