# =========================================================================
# Cell 2: Lọc nhiễu theo residual
# =========================================================================
PERCENTILE_TO_REMOVE = 10
TARGET_VARIABLE = 'agbd'
YEAR_TO_CALCULATE = 5

FOLDER_PATH = '/content/drive/MyDrive/data/trainingData/'
EXPORT_PATH = '/content/drive/MyDrive/data/Biomass_all_Model_Training/'
FILE_NAME = 'biomass_predicted_data_50_cleaned_P90.csv'
FULL_INPUT_PATH = os.path.join(FOLDER_PATH, FILE_NAME)

print(f"Lọc {PERCENTILE_TO_REMOVE}% outliers từ: {FILE_NAME}")

# Tải dữ liệu
df = pd.read_csv(FULL_INPUT_PATH)
df.dropna(inplace=True)
n_original = len(df)

# Train model thăm dò
X = df.drop(columns=[TARGET_VARIABLE])
y = df[TARGET_VARIABLE]

initial_model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)
initial_model.fit(X, y)

# Tính residual
predictions = initial_model.predict(X)
df['residual'] = y - predictions

# Lọc theo percentile
lower_pct = PERCENTILE_TO_REMOVE / 2
upper_pct = 100 - (PERCENTILE_TO_REMOVE / 2)

lower_bound = np.percentile(df['residual'], lower_pct)
upper_bound = np.percentile(df['residual'], upper_pct)

mask_valid = (df['residual'] >= lower_bound) & (df['residual'] <= upper_bound)
df_cleaned = df[mask_valid].copy()
df_cleaned.drop(columns=['residual'], inplace=True)

n_cleaned = len(df_cleaned)
n_removed = n_original - n_cleaned

# Split train/test
df_train, df_test = train_test_split(df_cleaned, test_size=0.2, random_state=42)

# Export
train_file = os.path.join(EXPORT_PATH, f'train_filtered_for_{YEAR_TO_CALCULATE}_years_{PERCENTILE_TO_REMOVE}.csv')
test_file = os.path.join(EXPORT_PATH, f'val_filtered_for_{YEAR_TO_CALCULATE}_years_{PERCENTILE_TO_REMOVE}.csv')
metadata_file = os.path.join(EXPORT_PATH, f'filter_metadata_final_for_{YEAR_TO_CALCULATE}_years.joblib')

df_train.to_csv(train_file, index=False)
df_test.to_csv(test_file, index=False)

# Metadata
metadata = {
    'percentile_removed': PERCENTILE_TO_REMOVE,
    'n_original': n_original,
    'n_cleaned': n_cleaned,
    'n_removed': n_removed,
    'pct_removed': (n_removed / n_original) * 100,
    'n_train': len(df_train),
    'n_test': len(df_test),
    'lower_bound': lower_bound,
    'upper_bound': upper_bound,
    'target_variable': TARGET_VARIABLE
}

joblib.dump(metadata, metadata_file)

print(f"Ban đầu: {n_original:,} -> Sau lọc: {n_cleaned:,} ({n_removed:,} bỏ)")
print(f"Train: {len(df_train):,} | Test: {len(df_test):,}")